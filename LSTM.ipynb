{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, vocabulary_size=200, num_nodes=128, batch_size=10):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.reuse = False\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.num_nodes = num_nodes\n",
    "        with tf.variable_scope(\"LSTM_var\",reuse=self.reuse):\n",
    "            with tf.variable_scope(\"input_gate\"):\n",
    "                self.ix = tf.get_variable(\"ix\", [vocabulary_size, num_nodes], \n",
    "                                      tf.float32, tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.im = tf.get_variable(\"im\", [num_nodes, num_nodes], \n",
    "                                      tf.float32, tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.ib = tf.get_variable(\"ib\", [num_nodes], \n",
    "                                      tf.float32, tf.constant_initializer(0))\n",
    "            with tf.variable_scope(\"forget_gate\"):\n",
    "                self.fx = tf.get_variable(\"fx\", [vocabulary_size, num_nodes], tf.float32, \n",
    "                                     tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.fm = tf.get_variable(\"fm\", [num_nodes, num_nodes], \n",
    "                                      tf.float32, tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.fb = tf.get_variable(\"fb\", [num_nodes], \n",
    "                                     tf.float32, tf.constant_initializer(0))\n",
    "            \n",
    "            with tf.variable_scope(\"output_gate\"):\n",
    "                self.ox = tf.get_variable(\"ox\", [vocabulary_size, num_nodes], tf.float32, \n",
    "                                     tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.om = tf.get_variable(\"om\", [num_nodes, num_nodes], \n",
    "                                      tf.float32, tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.ob = tf.get_variable(\"ob\", [num_nodes], \n",
    "                                     tf.float32, tf.constant_initializer(0))\n",
    "            \n",
    "            with tf.variable_scope(\"memory_cell\"):\n",
    "                self.cx = tf.get_variable(\"cx\", [vocabulary_size, num_nodes], tf.float32, \n",
    "                                     tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.cm = tf.get_variable(\"cm\", [num_nodes, num_nodes], \n",
    "                                      tf.float32, tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.cb = tf.get_variable(\"cb\", [num_nodes], \n",
    "                                     tf.float32, tf.constant_initializer(0))\n",
    "                \n",
    "            with tf.variable_scope(\"output_layer\"):\n",
    "                self.w = tf.get_variable(\"w\", [num_nodes, vocabulary_size], tf.float32,\n",
    "                                        tf.truncated_normal_initializer(stddev=0.1))\n",
    "                self.b = tf.get_variable(\"b\", [vocabulary_size], tf.float32,\n",
    "                                        tf.constant_initializer(0))\n",
    "            \n",
    "            self.saved_output = tf.get_variable(\"saved_output\", [batch_size, num_nodes], tf.float32,\n",
    "                                        tf.truncated_normal_initializer(stddev=0.1), trainable=False)\n",
    "            self.saved_state = tf.get_variable(\"saved_state\", [batch_size, num_nodes], tf.float32,\n",
    "                                        tf.truncated_normal_initializer(stddev=0.1), trainable=False)\n",
    "            \n",
    "        self.variables = tf.get_collection(tf.GraphKeys.VARIABLES, scope=\"LSTM_var\")\n",
    "        \n",
    "    def lstm_cell(self, inputs, hidden_layer, state):         \n",
    "        with tf.variable_scope(\"LSTM_CELL\",reuse=self.reuse):\n",
    "            input_gate = tf.sigmoid(tf.matmul(inputs, self.ix) + tf.matmul(hidden_layer, self.im) + self.ib,\n",
    "                                    name=\"input_gate\")\n",
    "            forget_gate = tf.sigmoid(tf.matmul(inputs, self.fx) + tf.matmul(hidden_layer, self.fm) + self.fb,\n",
    "                                    name=\"forget_gate\")\n",
    "            update_gate = tf.tanh(tf.matmul(inputs, self.cx) + tf.matmul(hidden_layer, self.cm) + self.cb,\n",
    "                            name=\"update_gate\")\n",
    "            state = tf.add(tf.mul(forget_gate, state), tf.mul(input_gate, update_gate),\n",
    "                           name=\"state\")\n",
    "            output_gate = tf.sigmoid(tf.matmul(inputs, self.ox) + tf.matmul(hidden_layer, self.om) + self.ob,\n",
    "                                     name=\"output_gate\") \n",
    "            output = tf.mul(output_gate, tf.tanh(state), name=\"output\")\n",
    "            \n",
    "        return output, state   \n",
    "    \n",
    "    def model(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        self.model(inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = tf.Variable(tf.truncated_normal((1,128)))\n",
    "state = tf.Variable(tf.truncated_normal((1,128)))\n",
    "test_inputs = tf.placeholder(tf.float32, shape=[1, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'LSTM_CELL/output:0' shape=(1, 128) dtype=float32>,\n",
       " <tf.Tensor 'LSTM_CELL/state:0' shape=(1, 128) dtype=float32>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.lstm_cell(test_inputs, h, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_var/input_gate/ix:0,(200, 128)\n",
      "LSTM_var/input_gate/im:0,(128, 128)\n",
      "LSTM_var/input_gate/ib:0,(128,)\n",
      "LSTM_var/forget_gate/fx:0,(200, 128)\n",
      "LSTM_var/forget_gate/fm:0,(128, 128)\n",
      "LSTM_var/forget_gate/fb:0,(128,)\n",
      "LSTM_var/output_gate/ox:0,(200, 128)\n",
      "LSTM_var/output_gate/om:0,(128, 128)\n",
      "LSTM_var/output_gate/ob:0,(128,)\n",
      "LSTM_var/memory_cell/cx:0,(200, 128)\n",
      "LSTM_var/memory_cell/cm:0,(128, 128)\n",
      "LSTM_var/memory_cell/cb:0,(128,)\n",
      "LSTM_var/output_layer/w:0,(128, 200)\n",
      "LSTM_var/output_layer/b:0,(200,)\n",
      "LSTM_var/saved_output:0,(10, 128)\n",
      "LSTM_var/saved_state:0,(10, 128)\n"
     ]
    }
   ],
   "source": [
    "for i in L.variables:\n",
    "    print(\"{},{}\".format(i.name, i.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tf]",
   "language": "python",
   "name": "Python [tf]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
