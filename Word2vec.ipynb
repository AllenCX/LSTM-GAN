{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "import logging\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus(\"data/text8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-09 22:58:29,247 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2016-10-09 22:58:29,248 : INFO : collecting all words and their counts\n",
      "2016-10-09 22:58:29,306 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2016-10-09 22:58:33,663 : INFO : collected 253855 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2016-10-09 22:58:33,999 : INFO : min_count=5 retains 71290 unique words (drops 182565)\n",
      "2016-10-09 22:58:33,999 : INFO : min_count leaves 16718843 word corpus (98% of original 17005207)\n",
      "2016-10-09 22:58:34,140 : INFO : deleting the raw counts dictionary of 253855 items\n",
      "2016-10-09 22:58:34,153 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2016-10-09 22:58:34,153 : INFO : downsampling leaves estimated 12506278 word corpus (74.8% of prior 16718843)\n",
      "2016-10-09 22:58:34,154 : INFO : estimated required memory for 71290 words and 2 dimensions: 36785640 bytes\n",
      "2016-10-09 22:58:34,349 : INFO : resetting layer weights\n",
      "2016-10-09 22:58:35,031 : INFO : training model with 5 workers on 71290 vocabulary and 2 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2016-10-09 22:58:35,032 : INFO : expecting 1701 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-10-09 22:58:36,037 : INFO : PROGRESS: at 2.62% examples, 1622616 words/s, in_qsize 0, out_qsize 0\n",
      "2016-10-09 22:58:37,040 : INFO : PROGRESS: at 5.29% examples, 1645223 words/s, in_qsize 0, out_qsize 0\n",
      "2016-10-09 22:58:38,043 : INFO : PROGRESS: at 7.94% examples, 1652292 words/s, in_qsize 0, out_qsize 0\n",
      "2016-10-09 22:58:39,045 : INFO : PROGRESS: at 10.58% examples, 1654136 words/s, in_qsize 0, out_qsize 0\n",
      "2016-10-09 22:58:40,045 : INFO : PROGRESS: at 12.95% examples, 1619585 words/s, in_qsize 9, out_qsize 1\n",
      "2016-10-09 22:58:41,049 : INFO : PROGRESS: at 15.38% examples, 1600917 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:58:42,050 : INFO : PROGRESS: at 17.81% examples, 1588726 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:58:43,057 : INFO : PROGRESS: at 20.24% examples, 1577367 words/s, in_qsize 9, out_qsize 1\n",
      "2016-10-09 22:58:44,058 : INFO : PROGRESS: at 22.65% examples, 1568022 words/s, in_qsize 9, out_qsize 1\n",
      "2016-10-09 22:58:45,061 : INFO : PROGRESS: at 25.07% examples, 1562465 words/s, in_qsize 9, out_qsize 1\n",
      "2016-10-09 22:58:46,061 : INFO : PROGRESS: at 27.47% examples, 1558373 words/s, in_qsize 10, out_qsize 0\n",
      "2016-10-09 22:58:47,062 : INFO : PROGRESS: at 29.90% examples, 1555783 words/s, in_qsize 10, out_qsize 0\n",
      "2016-10-09 22:58:48,065 : INFO : PROGRESS: at 32.33% examples, 1553280 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-09 22:58:49,069 : INFO : PROGRESS: at 34.78% examples, 1551581 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:58:50,069 : INFO : PROGRESS: at 37.23% examples, 1548733 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-09 22:58:51,071 : INFO : PROGRESS: at 39.64% examples, 1545625 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-09 22:58:52,071 : INFO : PROGRESS: at 42.07% examples, 1543549 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:58:53,074 : INFO : PROGRESS: at 44.51% examples, 1542407 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:58:54,081 : INFO : PROGRESS: at 46.96% examples, 1542199 words/s, in_qsize 9, out_qsize 1\n",
      "2016-10-09 22:58:55,086 : INFO : PROGRESS: at 49.39% examples, 1541140 words/s, in_qsize 6, out_qsize 2\n",
      "2016-10-09 22:58:56,087 : INFO : PROGRESS: at 51.84% examples, 1540747 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-09 22:58:57,088 : INFO : PROGRESS: at 54.26% examples, 1539763 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-09 22:58:58,096 : INFO : PROGRESS: at 56.72% examples, 1538343 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-09 22:58:59,107 : INFO : PROGRESS: at 59.17% examples, 1537154 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:59:00,115 : INFO : PROGRESS: at 61.62% examples, 1536137 words/s, in_qsize 6, out_qsize 1\n",
      "2016-10-09 22:59:01,125 : INFO : PROGRESS: at 64.08% examples, 1535370 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-09 22:59:02,132 : INFO : PROGRESS: at 66.51% examples, 1535084 words/s, in_qsize 7, out_qsize 3\n",
      "2016-10-09 22:59:03,136 : INFO : PROGRESS: at 68.96% examples, 1535024 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:59:04,136 : INFO : PROGRESS: at 71.38% examples, 1534571 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-09 22:59:05,136 : INFO : PROGRESS: at 73.82% examples, 1534297 words/s, in_qsize 9, out_qsize 0\n",
      "2016-10-09 22:59:06,140 : INFO : PROGRESS: at 76.28% examples, 1533864 words/s, in_qsize 6, out_qsize 0\n",
      "2016-10-09 22:59:07,142 : INFO : PROGRESS: at 78.71% examples, 1533027 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-09 22:59:08,149 : INFO : PROGRESS: at 81.15% examples, 1532330 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-09 22:59:09,157 : INFO : PROGRESS: at 83.62% examples, 1532101 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-09 22:59:10,166 : INFO : PROGRESS: at 86.07% examples, 1531949 words/s, in_qsize 8, out_qsize 2\n",
      "2016-10-09 22:59:11,171 : INFO : PROGRESS: at 88.50% examples, 1531779 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-09 22:59:12,183 : INFO : PROGRESS: at 90.96% examples, 1531638 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-09 22:59:13,188 : INFO : PROGRESS: at 93.39% examples, 1531260 words/s, in_qsize 7, out_qsize 2\n",
      "2016-10-09 22:59:14,189 : INFO : PROGRESS: at 95.84% examples, 1530824 words/s, in_qsize 8, out_qsize 1\n",
      "2016-10-09 22:59:15,197 : INFO : PROGRESS: at 98.31% examples, 1530803 words/s, in_qsize 7, out_qsize 1\n",
      "2016-10-09 22:59:15,871 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2016-10-09 22:59:15,872 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-10-09 22:59:15,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-10-09 22:59:15,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-10-09 22:59:15,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-10-09 22:59:15,876 : INFO : training on 85026035 raw words (62534371 effective words) took 40.8s, 1531076 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, size=2, window=5, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.55509591,  1.26409554], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['uk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c34ae94240a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/word2vec_2D.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"models/word2vec_2D.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-11 20:59:25,134 : INFO : loading Word2Vec object from models/word2vec_2D.model\n",
      "2016-10-11 20:59:25,359 : INFO : setting ignored attribute syn0norm to None\n",
      "2016-10-11 20:59:25,364 : INFO : setting ignored attribute cum_table to None\n"
     ]
    }
   ],
   "source": [
    "word_model = gensim.models.Word2Vec.load(\"models/word2vec_2D.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = np.zeros(shape=[len(word_model.vocab), 2])\n",
    "id2word = dict()\n",
    "word2id = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,k in enumerate(word_model.vocab.keys()):\n",
    "    id2word[i] = k\n",
    "    word2id[k] = i\n",
    "    matrix[i] = word_model[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = tf.constant(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emd = tf.nn.embedding_lookup(embedding_matrix, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    em = sess.run(emd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73015785,  1.44113648])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"embedding_matrix_2D\", 'wb') as f:\n",
    "    pickle.dump([matrix, id2word, word2id], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y, z = pickle.load(open(\"embedding_matrix_2D\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16928734,  0.56346083],\n",
       "       [ 0.73015785,  1.44113648],\n",
       "       [ 0.25020877,  0.45025212],\n",
       "       ..., \n",
       "       [ 3.04497743,  1.08371174],\n",
       "       [ 0.45141   ,  0.76665598],\n",
       "       [-0.18308809,  0.90003824]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tf]",
   "language": "python",
   "name": "Python [tf]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
